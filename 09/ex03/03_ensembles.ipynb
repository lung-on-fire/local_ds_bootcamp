{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1686, 44)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n",
    "enrichment = pd.read_csv('../data/dayofweek.csv')\n",
    "df['dayofweek'] = enrichment['dayofweek']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('dayofweek', axis=1), df['dayofweek'], test_size=0.2, random_state=21, stratify=df['dayofweek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=21, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_on_valid_set(model, X_train, y_train, X_valid, y_valid, **kwargs) -> None:\n",
    "    if kwargs:\n",
    "        model.set_params(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    prec = precision_score(y_valid, y_pred, average='weighted')\n",
    "    rcl = recall_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"accuracy is {acc:.5f}\")\n",
    "    print(f\"precision is {prec:.5f}\")\n",
    "    print(f\"recall is {rcl:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.87778\n",
      "precision is 0.88162\n",
      "recall is 0.87778\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC(random_state=21, probability=True, C=10, class_weight=None, gamma='auto', kernel= 'rbf')\n",
    "metrics_on_valid_set(SVM_model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.86667\n",
      "precision is 0.87170\n",
      "recall is 0.86667\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=21, max_depth=21, criterion='gini', class_weight='balanced')\n",
    "metrics_on_valid_set(tree_model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89630\n",
      "precision is 0.89698\n",
      "recall is 0.89630\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(random_state=21, n_estimators=100, max_depth=24, criterion='entropy', class_weight='balanced')\n",
    "metrics_on_valid_set(forest_model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90000\n",
      "precision is 0.89993\n",
      "recall is 0.90000\n"
     ]
    }
   ],
   "source": [
    "clf = VotingClassifier(estimators=[('svc', SVM_model), ('dtc', tree_model), ('rf', forest_model)], voting='hard')\n",
    "metrics_on_valid_set(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.88519\n",
      "precision is 0.88840\n",
      "recall is 0.88519\n"
     ]
    }
   ],
   "source": [
    "clf = VotingClassifier(estimators=[('svc', SVM_model), ('dtc', tree_model), ('rf', forest_model)], voting='soft')\n",
    "metrics_on_valid_set(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'weights_combination': (4, 1, 4), 'voting': 'soft'}\n",
      "Best accuracy is 0.91111 with weights (4, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_prec = 0\n",
    "best_weights = ()\n",
    "best_model = None\n",
    "param_grid = {\n",
    "    'weights_combination' : [\n",
    "    (1,1,1),\n",
    "    (2,1,1),\n",
    "    (1,2,1),\n",
    "    (1,1,2),\n",
    "    (3,2,1),\n",
    "    (1,2,3),\n",
    "    (4,1,4)\n",
    "    ],\n",
    "    'voting' : ['soft', 'hard']\n",
    "}\n",
    "\n",
    "for weights in param_grid['weights_combination']:\n",
    "    for voting in param_grid['voting']:\n",
    "        clf = VotingClassifier(estimators=[('svc', SVM_model), ('dtc', tree_model), ('rf', forest_model)], voting=voting, weights=weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_valid)\n",
    "\n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "        prec = precision_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "        if ((acc > best_acc) or (acc==best_acc and prec > best_prec)):\n",
    "            best_acc = acc\n",
    "            best_weights = weights\n",
    "            best_model = clf\n",
    "            best_params = {\n",
    "                'weights_combination': weights,\n",
    "                'voting': voting\n",
    "            }\n",
    "\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best accuracy is {best_acc:.5f} with weights {best_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90533\n",
      "precision is 0.90881\n",
      "recall is 0.90533\n"
     ]
    }
   ],
   "source": [
    "clf = VotingClassifier(estimators=[('svc', SVM_model), ('dtc', tree_model), ('rf', forest_model)], voting='soft', weights=best_weights)\n",
    "metrics_on_valid_set(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.88519\n",
      "precision is 0.89258\n",
      "recall is 0.88519\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC(random_state=21, probability=True, C=10, class_weight=None, gamma='auto', kernel= 'rbf')\n",
    "clf = BaggingClassifier(SVM_model, n_estimators=20, random_state=21)\n",
    "metrics_on_valid_set(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8740740740740741 and precision is 0.8842291933481172 with 5 estimators\n",
      "Accuracy is 0.8851851851851852 and precision is 0.8942694727247573 with 10 estimators\n",
      "Accuracy is 0.8851851851851852 and precision is 0.8925755778956984 with 20 estimators\n",
      "Accuracy is 0.8814814814814815 and precision is 0.8903537908921018 with 50 estimators\n",
      "Accuracy is 0.8851851851851852 and precision is 0.8939608307494487 with 100 estimators\n",
      "Best accuracy is 0.88519 with 10 estimators\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_n = 0\n",
    "best_prec = 0\n",
    "for n in (5,10,20,50,100):\n",
    "    clf = BaggingClassifier(SVM_model, n_estimators=n, random_state=21)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    prec = precision_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "    if ((acc > best_acc) or (acc==best_acc and prec > best_prec)):\n",
    "        best_acc = acc\n",
    "        best_n = n\n",
    "        best_prec = prec\n",
    "    print(f\"Accuracy is {acc} and precision is {prec} with {n} estimators\")\n",
    "\n",
    "print(f\"Best accuracy is {best_acc:.5f} with {best_n} estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.86391\n",
      "precision is 0.86966\n",
      "recall is 0.86391\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(SVM_model, n_estimators=best_n, random_state=21)\n",
    "metrics_on_valid_set(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('svc', SVM_model),\n",
    "    ('dtc', tree_model),\n",
    "    ('rf', forest_model)\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(solver='liblinear', random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_splits': 4, 'passthrough': True}\n",
      "Best Accuracy: 0.9111\n",
      "Best Precision: 0.9133\n"
     ]
    }
   ],
   "source": [
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_model = None\n",
    "\n",
    "param_grid = {\n",
    "    'n_splits': [2, 3, 4, 5, 6, 7],\n",
    "    'passthrough': [False, True]\n",
    "}\n",
    "\n",
    "for n_splits in param_grid['n_splits']:\n",
    "    for passthrough in param_grid['passthrough']:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "        \n",
    "        stack_clf = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=final_estimator,\n",
    "            cv=cv,\n",
    "            passthrough=passthrough\n",
    "        )\n",
    "        \n",
    "        stack_clf.fit(X_train, y_train)\n",
    "        y_pred = stack_clf.predict(X_valid)\n",
    "        \n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "        prec = precision_score(y_valid, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_valid, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "\n",
    "        if (acc > best_accuracy) or (acc == best_accuracy and prec > best_precision):\n",
    "            best_accuracy = acc\n",
    "            best_precision = prec\n",
    "            best_params = {\n",
    "                'n_splits': n_splits,\n",
    "                'passthrough': passthrough\n",
    "            }\n",
    "            best_model = stack_clf\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Precision: {best_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90533\n",
      "precision is 0.90844\n",
      "recall is 0.90533\n"
     ]
    }
   ],
   "source": [
    "metrics_on_valid_set(best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = VotingClassifier(estimators=[('svc', SVM_model), ('dtc', tree_model), ('rf', forest_model)], voting='hard', weights=(4, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df.drop('dayofweek', axis=1)\n",
    "y_full = df['dayofweek']\n",
    "\n",
    "X_new_train = pd.concat([X_train, X_valid])\n",
    "y_new_train = pd.concat([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rates by Weekday (%):\n",
      "true_value\n",
      "0    5.147059\n",
      "4    2.884615\n",
      "1    2.189781\n",
      "5    1.476015\n",
      "2    1.342282\n",
      "3    1.010101\n",
      "6    0.561798\n",
      "Name: is_error, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_clf.fit(X_new_train, y_new_train)\n",
    "y_pred = best_clf.predict(X_full)\n",
    "\n",
    "test_data = X_full.copy()\n",
    "test_data['true_value'] = y_full\n",
    "test_data['predicted_value'] = y_pred\n",
    "test_data['is_error'] = (y_full != y_pred).astype(int)\n",
    "\n",
    "error_rates_by_weekday = test_data.groupby('true_value')['is_error'].mean() * 100\n",
    "print(\"Error Rates by Weekday (%):\")\n",
    "print(error_rates_by_weekday.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_voting_classifier.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_clf,'best_model_voting_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shylaisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
